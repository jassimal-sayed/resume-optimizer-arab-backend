"""Alembic configuration entrypoint for orchestrator service."""

# ruff: noqa: F401

import asyncio
import sys
from logging.config import fileConfig
from pathlib import Path

from alembic import context
from sqlalchemy import pool
from sqlalchemy.ext.asyncio import async_engine_from_config

# Ensure project root on sys.path
PROJECT_ROOT = Path(__file__).resolve().parents[3]
sys.path.insert(0, str(PROJECT_ROOT))

# Load environment variables from .env.dev or .env.prod
from dotenv import load_dotenv

env_file = PROJECT_ROOT / ".env.dev"
if not env_file.exists():
    env_file = PROJECT_ROOT / ".env.prod"
if env_file.exists():
    load_dotenv(env_file)

from libs.common.config import get_settings
from libs.db.base import Base

# Import all models to register them with Base.metadata
from services.orchestrator_service.app.db.models import (
    Job,
    Optimization,
    Resume,
    ResumeVersion,
    TaskQueue,
    WorkflowToken,
)

settings = get_settings()
config = context.config

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

target_metadata = Base.metadata

# All tables owned by orchestrator service
SERVICE_TABLES = {
    "resumes",
    "resume_versions",
    "jobs",
    "optimizations",
    "task_queue",
    "workflow_tokens",
}

url = settings.DATABASE_URL.replace("%", "%%")
config.set_main_option("sqlalchemy.url", url)


def include_object(obj, name, type_, reflected, compare_to):
    """Filter objects to only include tables owned by this service."""
    if type_ == "table":
        return name in SERVICE_TABLES
    if type_ in ("index", "column", "foreign_key_constraint"):
        return obj.table.name in SERVICE_TABLES
    return True


def run_migrations_offline() -> None:
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        version_table="alembic_version_academy",
        include_object=include_object,
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection):
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        version_table="alembic_version_academy",
        include_object=include_object,
    )
    with context.begin_transaction():
        context.run_migrations()


async def run_migrations_online() -> None:
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
        # Disable psycopg auto-prepared statements to avoid duplicate name errors
        connect_args={"prepare_threshold": 0},
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


if context.is_offline_mode():
    run_migrations_offline()
else:
    asyncio.run(run_migrations_online())
